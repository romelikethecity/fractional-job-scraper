name: Daily Fractional Job Scrape

on:
  schedule:
    # Run at 6 AM UTC daily (1 AM EST, 10 PM PST)
    - cron: '0 6 * * *'
  workflow_dispatch:  # Allow manual triggers

env:
  PYTHON_VERSION: '3.11'

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Download existing database
        uses: actions/download-artifact@v4
        with:
          name: fractional-jobs-db
          path: .
        continue-on-error: true  # First run won't have existing DB
      
      - name: Run daily scrape
        run: |
          python main.py --action scrape --source all --max-pages 3
        env:
          DATABASE_URL: sqlite:///fractional_jobs.db
      
      - name: Create daily snapshot
        run: |
          python main.py --action snapshot
      
      - name: Export CSV
        run: |
          python main.py --action export
      
      - name: Upload database artifact
        uses: actions/upload-artifact@v4
        with:
          name: fractional-jobs-db
          path: fractional_jobs.db
          retention-days: 90
      
      - name: Upload CSV to output branch
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          
          # Create output directory structure
          mkdir -p docs/data
          cp output/data/*.csv docs/data/ 2>/dev/null || true
          
          # Commit and push to main branch
          git add docs/data/*.csv
          git diff --staged --quiet || git commit -m "Update job listings $(date +%Y-%m-%d)"
          git push
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  weekly-report:
    runs-on: ubuntu-latest
    needs: scrape
    if: github.event.schedule == '0 6 * * 0'  # Only on Sundays
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: pip install -r requirements.txt
      
      - name: Download database
        uses: actions/download-artifact@v4
        with:
          name: fractional-jobs-db
          path: .
      
      - name: Generate weekly summary
        run: |
          python main.py --action weekly > weekly_summary.json
      
      - name: Create compensation snapshots
        run: |
          python -c "
          from main import FractionalJobOrchestrator
          o = FractionalJobOrchestrator()
          snapshots = o.create_compensation_snapshot()
          print(f'Created {len(snapshots)} compensation snapshots')
          "
      
      - name: Upload weekly summary
        uses: actions/upload-artifact@v4
        with:
          name: weekly-summary-${{ github.run_number }}
          path: weekly_summary.json
          retention-days: 30
